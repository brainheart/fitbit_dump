import os
import sys
import json
import uuid
import datetime as dt
import urllib.parse
import webbrowser
import http.server
import socketserver
import requests
import pandas as pd
import csv
import argparse
from dotenv import load_dotenv

"""
Fitbit Daily Exporter (zero‚Äëmanual‚Äëtoken edition)
=================================================
Export the last *n* days (default 8) of daily Fitbit metrics to a CSV with columns:

    Date, Weight, Calories Burned, Steps, Sleep Start Time, Sleep Stop Time, Minutes Asleep

This version automates the OAuth flow: on the first run it pops open a browser,
captures the redirect on a tiny local server, stores tokens in *tokens.json*,
and refreshes them silently on subsequent runs.

Setup
-----
1. Create a *Personal* Fitbit dev app ‚Üí set callback `http://127.0.0.1:8080/`.
2. Scopes **activity sleep weight profile**.
3. `.env` file with:

       FITBIT_CLIENT_ID=<id>
       FITBIT_CLIENT_SECRET=<secret>

4. `pip install requests pandas python-dotenv`.

Run
---
    python fitbit_export.py                      # 8 days ‚Üí fitbit_export-YYYY-MM-DD_to_YYYY-MM-DD.csv
    python fitbit_export.py --days 30            # 30 days ‚Üí fitbit_export-YYYY-MM-DD_to_YYYY-MM-DD.csv
    python fitbit_export.py --start 2025-04-01 --end 2025-04-30  # Specific date range
    python fitbit_export.py --date 2025-04-15    # Single date
    python fitbit_export.py --days 30 --desc     # Process from newest to oldest
    python fitbit_export.py --output custom.csv  # Use custom filename without date range
"""

load_dotenv()

CLIENT_ID = os.getenv("FITBIT_CLIENT_ID")
CLIENT_SECRET = os.getenv("FITBIT_CLIENT_SECRET")
TOKEN_URL = "https://api.fitbit.com/oauth2/token"
API_BASE = "https://api.fitbit.com"
CALLBACK_URI = "http://localhost:8080/"
TOKEN_FILE = "tokens.json"

# Default output filename without extension
DEFAULT_OUTPUT_BASE = "fitbit_export"

#----------------------------------------------------------------------
# Token helpers
#----------------------------------------------------------------------

def _load_tokens():
    if os.path.exists(TOKEN_FILE):
        with open(TOKEN_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}


def _save_tokens(tokens: dict):
    with open(TOKEN_FILE, "w", encoding="utf-8") as f:
        json.dump(tokens, f)

_tokens = _load_tokens()
ACCESS_TOKEN = _tokens.get("access_token")
REFRESH_TOKEN = _tokens.get("refresh_token")

_headers = lambda token: {"Authorization": f"Bearer {token}", "Accept-Language": "en_US"}

#----------------------------------------------------------------------
# Interactive authorisation (first‚Äërun only)
#----------------------------------------------------------------------
class _AuthHandler(http.server.BaseHTTPRequestHandler):
    """Capture the ?code=‚Ä¶ redirect & stash it on the server object."""
    server_version = "FitbitAuth/0.2"
    def log_message(self, *_):
        pass  # suppress default logging to stderr
    def do_GET(self):
        parsed = urllib.parse.urlparse(self.path)
        params = urllib.parse.parse_qs(parsed.query)
        if "code" in params:
            self.server.auth_code = params["code"][0]
            self.send_response(200)
            self.send_header("Content-Type", "text/html; charset=utf-8")
            self.end_headers()
            html = "<h1>Authorisation received ‚Äî you may close this window.</h1>"
            self.wfile.write(html.encode("utf-8"))
        else:
            self.send_error(400, "Missing code parameter")


def _interactive_authorise() -> dict:
    print("üîë  Opening browser for Fitbit consent‚Ä¶")
    state = uuid.uuid4().hex
    params = {
        "response_type": "code",
        "client_id": CLIENT_ID,
        "redirect_uri": CALLBACK_URI,
        "scope": "activity sleep weight profile",
        "state": state,
        "expires_in": 604800,
    }
    webbrowser.open(f"https://www.fitbit.com/oauth2/authorize?{urllib.parse.urlencode(params)}")

    with socketserver.TCPServer(("", 8080), _AuthHandler) as httpd:
        httpd.auth_code = None
        while httpd.auth_code is None:
            httpd.handle_request()
        code = httpd.auth_code

    auth = (CLIENT_ID, CLIENT_SECRET)
    data = {
        "grant_type": "authorization_code",
        "client_id": CLIENT_ID,
        "code": code,
        "redirect_uri": CALLBACK_URI,
    }
    resp = requests.post(TOKEN_URL, auth=auth, data=data)
    resp.raise_for_status()
    tokens = resp.json()
    _save_tokens(tokens)
    print("‚úÖ  Tokens saved to tokens.json")
    return tokens

#----------------------------------------------------------------------
# Token refresh
#----------------------------------------------------------------------

def _refresh_access_token():
    global ACCESS_TOKEN, REFRESH_TOKEN
    auth = (CLIENT_ID, CLIENT_SECRET)
    data = {"grant_type": "refresh_token", "refresh_token": REFRESH_TOKEN}
    resp = requests.post(TOKEN_URL, auth=auth, data=data)
    resp.raise_for_status()
    tokens = resp.json()
    ACCESS_TOKEN = tokens["access_token"]
    REFRESH_TOKEN = tokens["refresh_token"]
    _save_tokens(tokens)


def _get(url: str) -> dict:
    resp = requests.get(url, headers=_headers(ACCESS_TOKEN))
    if resp.status_code == 401:
        _refresh_access_token()
        resp = requests.get(url, headers=_headers(ACCESS_TOKEN))
    resp.raise_for_status()
    return resp.json()

#----------------------------------------------------------------------
# Metric fetchers
#----------------------------------------------------------------------

def _fetch_day(date_str: str) -> dict:
    print(f"üìÜ Fetching data for {date_str}...")
    wt = _get(f"{API_BASE}/1/user/-/body/log/weight/date/{date_str}.json")
    weight = wt["weight"][-1]["weight"] if wt["weight"] else None

    act = _get(f"{API_BASE}/1/user/-/activities/date/{date_str}.json")
    steps = act["summary"].get("steps")
    calories = act["summary"].get("caloriesOut")

    slp = _get(f"{API_BASE}/1.2/user/-/sleep/date/{date_str}.json")
    sleep_start = sleep_end = minutes_asleep = None
    if slp.get("sleep"):
        main = next((l for l in slp["sleep"] if l.get("isMainSleep")), slp["sleep"][0])
        sleep_start, sleep_end, minutes_asleep = main["startTime"], main["endTime"], main["minutesAsleep"]

    return {
        "Date": date_str,
        "Sleep Start Time": sleep_start,
        "Sleep Stop Time": sleep_end,
        "Minutes Asleep": minutes_asleep,
        "Steps": steps,
        "Calories Burned": calories,
        "Weight": weight,
    }

#----------------------------------------------------------------------
# Export logic
#----------------------------------------------------------------------

def generate_output_filename(date_range, user_specified_filename=None):
    """
    Generate a filename that includes the date range.
    If user specified a filename, use that instead.
    
    Args:
        date_range: List of date objects
        user_specified_filename: User-provided filename (optional)
        
    Returns:
        Filename string with date range (if applicable)
    """
    if user_specified_filename:
        return user_specified_filename
        
    # Find the min and max dates
    if not date_range:
        return f"{DEFAULT_OUTPUT_BASE}.csv"
        
    min_date = min(date_range).isoformat()
    max_date = max(date_range).isoformat()
    
    # Create filename with date range
    return f"{DEFAULT_OUTPUT_BASE}-{min_date}_to_{max_date}.csv"

def export_data(date_range: list, outfile: str = None, ascending: bool = True, include_date_range: bool = True):
    """
    Export Fitbit data for the given date range to a CSV file.
    Writes data incrementally, one row at a time.
    
    Args:
        date_range: List of date objects to process
        outfile: Output CSV filename or None to auto-generate
        ascending: If True, process dates from oldest to newest; if False, process newest to oldest
        include_date_range: If True and outfile is None, include date range in filename
    """
    # Generate appropriate filename if not explicitly provided
    if include_date_range and outfile is None:
        outfile = generate_output_filename(date_range)
    elif outfile is None:
        outfile = f"{DEFAULT_OUTPUT_BASE}.csv"
    
    # CSV column headers
    columns = ["Date", "Sleep Start Time", "Sleep Stop Time", "Minutes Asleep", "Steps", "Calories Burned", "Weight"]
    
    # Create new CSV file with headers or append to existing if it exists
    file_exists = os.path.exists(outfile)
    
    # Sort the date range based on the ascending parameter
    if ascending:
        # Sort from oldest to newest (ascending)
        date_range.sort()
        date_order = "oldest to newest"
    else:
        # Sort from newest to oldest (descending)
        date_range.sort(reverse=True)
        date_order = "newest to oldest"
        
    print(f"üîÑ Processing dates in {date_order} order")
    print(f"üìù Output file: {outfile}")
    
    with open(outfile, mode='a' if file_exists else 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=columns)
        
        # Write headers only if creating a new file
        if not file_exists:
            writer.writeheader()
        
        total_days = len(date_range)
        for i, date_obj in enumerate(date_range, 1):
            try:
                date_str = date_obj.isoformat()
                row_data = _fetch_day(date_str)
                
                # Write single row to CSV immediately
                writer.writerow(row_data)
                f.flush()  # Ensure data is written to disk immediately
                
                print(f"‚úì [{i}/{total_days}] Saved data for {date_str}")
            except Exception as e:
                print(f"‚ùå Error fetching data for {date_str}: {e}")
    
    print(f"‚ú® Completed! Data saved to {outfile}")


def generate_date_range(start_date, end_date):
    """Generate a list of dates between start_date and end_date (inclusive)."""
    delta = (end_date - start_date).days + 1
    return [start_date + dt.timedelta(days=i) for i in range(delta)]


def parse_date(date_str):
    """Parse date string in YYYY-MM-DD format."""
    try:
        return dt.date.fromisoformat(date_str)
    except ValueError:
        sys.exit(f"‚ùå Invalid date format: {date_str}. Please use YYYY-MM-DD format.")

#----------------------------------------------------------------------
# Entrypoint
#----------------------------------------------------------------------
if __name__ == "__main__":
    if not CLIENT_ID or not CLIENT_SECRET:
        sys.exit("‚ùå Add FITBIT_CLIENT_ID and FITBIT_CLIENT_SECRET to .env first!")

    if not (ACCESS_TOKEN and REFRESH_TOKEN):
        toks = _interactive_authorise()
        ACCESS_TOKEN, REFRESH_TOKEN = toks["access_token"], toks["refresh_token"]

    # Set up argument parser for more flexible date range options
    parser = argparse.ArgumentParser(description="Export Fitbit data to CSV")
    
    date_group = parser.add_mutually_exclusive_group()
    date_group.add_argument("--days", type=int, default=8,
                     help="Number of days to fetch from today (default: 8)")
    date_group.add_argument("--date", type=str,
                     help="Specific date to fetch (format: YYYY-MM-DD)")
    date_group.add_argument("--start", type=str,
                     help="Start date for range (format: YYYY-MM-DD)")
    
    parser.add_argument("--end", type=str,
                     help="End date for range (format: YYYY-MM-DD)")
    parser.add_argument("--output", type=str,
                     help="Output CSV filename (default: auto-generated with date range)")
    parser.add_argument("--no-date-in-filename", action="store_true",
                     help="Don't include date range in output filename")
    
    # Add sort order control - mutually exclusive group for asc/desc
    order_group = parser.add_mutually_exclusive_group()
    order_group.add_argument("--asc", action="store_true", 
                     help="Process dates from oldest to newest (default)")
    order_group.add_argument("--desc", action="store_true",
                     help="Process dates from newest to oldest")
                     
    # For backwards compatibility with positional args
    parser.add_argument("days_pos", nargs="?", type=int, 
                      help=argparse.SUPPRESS)
    parser.add_argument("output_pos", nargs="?", type=str,
                      help=argparse.SUPPRESS)

    args = parser.parse_args()

    # Handle backwards compatibility with positional arguments
    if args.days_pos is not None:
        args.days = args.days_pos
    if args.output_pos is not None:
        args.output = args.output_pos

    # Determine date range based on arguments
    today = dt.date.today()
    
    if args.date:
        # Single date
        single_date = parse_date(args.date)
        date_range = [single_date]
        print(f"üóìÔ∏è Fetching data for {args.date}")
    elif args.start:
        # Date range with explicit start
        start_date = parse_date(args.start)
        
        # If end date not provided, use today
        end_date = parse_date(args.end) if args.end else today
        
        if start_date > end_date:
            sys.exit("‚ùå Start date cannot be after end date")
            
        date_range = generate_date_range(start_date, end_date)
        print(f"üóìÔ∏è Fetching data from {start_date.isoformat()} to {end_date.isoformat()} ({len(date_range)} days)")
    else:
        # Default: last N days
        days = args.days
        date_range = [today - dt.timedelta(days=i) for i in range(days)]
        print(f"üóìÔ∏è Fetching data for the last {days} days")
    
    # Determine sort order (default is ascending - oldest to newest)
    ascending = not args.desc
    
    # Export the data
    include_date_range = not args.no_date_in_filename
    export_data(date_range, args.output, ascending, include_date_range)
